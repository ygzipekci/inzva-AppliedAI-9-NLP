{
  "cells": [
    {
      "id": "f633f33b-3d3f-4645-8f69-b9ef7638060f",
      "cell_type": "markdown",
      "source": [
        "# Dinozor NLP "
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "5df7d2c1-f23f-42b5-bf1a-ed72024d1327",
      "cell_type": "markdown",
      "source": [
        "Our goal is to to demonstrate an old NLP task with old NLP methodologies, to understand what the future methods are trying to do better. For this goal I found a Turkish SMS Spam detection dataset from [Onur Karasoy et al.](https://github.com/onrkrsy/TurkishSMS-Collection)"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "11f97e03-dd8e-4edb-9d37-247221cde9b3",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "dataset_path = Path(\"TurkishSMS-Collection/TurkishSMSCollection.csv\")\n",
        "df = pd.read_csv(dataset_path, sep=';')"
      ],
      "metadata": {}
    },
    {
      "id": "b7a38e12-7144-4496-9ce1-562a91140ae2",
      "cell_type": "markdown",
      "source": [
        "This is how the data looks like"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "3ea82aab-b032-420f-ba5c-32f561ee95fd",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "df"
      ],
      "metadata": {}
    },
    {
      "id": "f4340e55-bcc3-4a5d-85f5-28851940a244",
      "cell_type": "markdown",
      "source": [
        "The classes are balanced which is nice"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "b092cde8-c75e-4f1e-85b8-d62b5e381ce1",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "df.Group.value_counts()"
      ],
      "metadata": {}
    },
    {
      "id": "c36726fd-758b-4a13-be3e-73687b97c157",
      "cell_type": "markdown",
      "source": [
        "I am turning classes into 0 and 1 for convenience"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "711a3e12-f1fe-4272-b456-24170a70b170",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "df[\"Group\"] = df[\"Group\"].replace(2, 0)"
      ],
      "metadata": {}
    },
    {
      "id": "40852678-02b5-49f0-9c33-5f43a5092d50",
      "cell_type": "markdown",
      "source": [
        "## Good Old Feature Engineering\n",
        "\n",
        "Please Look at some samples and try to come up with some features that distinguish between spam and ham in this dataset. Than a bunch of classifiers will take those as inputs to generate scores. It is not about the results but the process of applying ancient ML methodologies for real life NLP problems."
      ],
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "attachments": {}
    },
    {
      "id": "89224001-3a10-403f-8eeb-d8e19ab996b8",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "pd.set_option('display.max_colwidth', None)"
      ],
      "metadata": {}
    },
    {
      "id": "97c14faf-3865-42ad-a2a0-a9c7fb825811",
      "cell_type": "markdown",
      "source": [
        "Take a look at random samples from each classes and try to come up with features that differanciates onw from the other"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "ea2f08f2-cc11-484a-b685-752a8d9815d9",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "df[df[\"Group\"] == 1].sample(5)"
      ],
      "metadata": {}
    },
    {
      "id": "158ba71b-fa5c-45ca-a297-a2473f5243f6",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "df[df[\"Group\"] == 0].sample(5)"
      ],
      "metadata": {}
    },
    {
      "id": "163098a4-2c0b-4de9-ab21-39b32e30bb30",
      "cell_type": "markdown",
      "source": [
        "### Exercise 1"
      ],
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "attachments": {}
    },
    {
      "id": "0b98e6c2-3dad-4f63-9ee5-e2009911c3b9",
      "cell_type": "markdown",
      "source": [
        "Below here, engineer some features and append them to the original dataframe like:\n",
        "\n",
        "```python\n",
        "def get_my_feature(text):\n",
        "    # calculate your galaxy brain feature\n",
        "    text = text.do_stuff()\n",
        "    return text\n",
        "\n",
        "df[\"my_feature\"] = df[\"Messages\"].apply(get_my_feature)\n",
        "```\n",
        "or in any way you like"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "a99ceefc-8eb1-4ce9-a62b-811b9673cc0f",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        ""
      ],
      "metadata": {}
    },
    {
      "id": "967f1da1-7494-4175-a020-6a4f5203bf87",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        ""
      ],
      "metadata": {}
    },
    {
      "id": "b6c22e3f-530c-4394-9f8d-08c35facb3a7",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        ""
      ],
      "metadata": {}
    },
    {
      "id": "bc18ef1f-2a10-4f1f-9fce-475e426c3163",
      "cell_type": "markdown",
      "source": [
        "take a look at your newly engineered features"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "c069d61a-3233-41a4-be04-5479eeffa3cd",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "df"
      ],
      "metadata": {}
    },
    {
      "id": "8315cdc3-f406-4b15-8532-6e6abf325757",
      "cell_type": "markdown",
      "source": [
        "### Lazy classifier\n",
        "\n",
        "Grinding different models to hit a higher score is automatable. What we are doing here is only meaningful during benchmarking, productionizing our solutions would bring up different concerns"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "dc702a57-4720-4ff8-ac2f-4fa0ce7b4938",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def train_test_split(df: pd.DataFrame, target: str, ratio: float=0.3): # i know i didn't need to write this\n",
        "    X = df.drop(target, axis=1)\n",
        "    Y = df[[target]]\n",
        "    split = round(len(df)*ratio)\n",
        "    X_test = X.iloc[:split]\n",
        "    X_train = X.iloc[split:]\n",
        "    y_test = Y.iloc[:split]\n",
        "    y_train = Y.iloc[split:]\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "metadata": {}
    },
    {
      "id": "ac8bd770-02c2-46af-96a8-9835dd54c0a0",
      "cell_type": "markdown",
      "source": [
        "I am using a library called lazy predict which is basically goes around and tries every sklearn classifier on your data, so that we can ignore model selection and hyperparameter tuning and just focus on the data"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "16bcc451-6d5a-4dd3-80e9-b0e3c06c97e9",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from lazypredict.Supervised import LazyClassifier\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "## write here your features along with the Group column\n",
        "features = df[[\"<put your features here alongside the Group column>\", \"Group\"]]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target=\"Group\", ratio=.3)\n",
        "\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=False, predictions=True, random_state=42, classifiers=\"all\", custom_metric=precision_score)\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {}
    },
    {
      "id": "43ae99a2-c79e-4565-8307-6a3294f76106",
      "cell_type": "markdown",
      "source": [
        "Let's make up a business rule and say that our spam filtering system must avoid flagging our loved ones' SMSs as spams."
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "ece9a345-39b2-4a06-92b2-808984f8e208",
      "cell_type": "markdown",
      "source": [
        "So let's compare classifiers by precision"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "818a389d-3da7-446c-adb0-3e100e473a53",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "models.sort_values(\"precision_score\", ascending=False)"
      ],
      "metadata": {}
    },
    {
      "id": "f0859145-70fa-4596-9859-ba66a61ae455",
      "cell_type": "markdown",
      "source": [
        "___"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "418752ad-fdf6-4769-ac95-667d56f10d74",
      "cell_type": "markdown",
      "source": [
        "Here is a simple error analysis view so you can see what sort of examples are predicted wrong and develop features based on your hypotheses"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "8ed341d0-f865-4fcd-b27b-0cdf318d0227",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "predictions[\"Group\"] = y_test\n",
        "highest_precision_classifier = models.sort_values(\"precision_score\", ascending=False).index[0]\n",
        "\n",
        "# the examples that were not spams but the best classifier decided otherwise\n",
        "indices = predictions[(predictions[\"Group\"] == 0) & (predictions[highest_precision_classifier] == 1)].index\n",
        "df.iloc[indices]"
      ],
      "metadata": {}
    },
    {
      "id": "5226b878-8058-44b3-bc7d-baa1d41f7ff6",
      "cell_type": "markdown",
      "source": [
        "What do you think could be improved?"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "b11a1552-7a02-436e-951f-125aa6f8e6ae",
      "cell_type": "markdown",
      "source": [
        "## Term document matrix"
      ],
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "attachments": {}
    },
    {
      "id": "a9cf3dcc-81b4-4b9e-95d1-2ff15360a582",
      "cell_type": "markdown",
      "source": [
        "Since the dawn of time, the goal of NLP research is to somehow represent language units with numbers. Because only then, we can make data science with them"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "f9af1fb0-a6eb-40d8-8159-1d177b66b07b",
      "cell_type": "markdown",
      "source": [
        "![xkcd](https://imgs.xkcd.com/comics/assigning_numbers.png)"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "dfdf5396-c8e4-4968-91cd-14e64f074689",
      "cell_type": "markdown",
      "source": [
        "One of the older ways to represent words (or tokens) and documents was to create a term-document matrix. We can assume in such matrix the rows are words and columns are documents, and the cells are a function of those two. The most basic function to use might be the frequency of that word in a document. With that we are representing each document with a vacabulary-size dimentional sparse vector. It is also called a co-occurance matrix. Words that co-occur are represented by vectors that are closer.  \n",
        "For example the words \"volkan\" and \"konak\" might occur together more often than \"volkan\" and \"şemsiye\"; Therefore distance(\"volkan\", \"konak\") < distance(\"volkan\", \"şemsiye)\n",
        "\n",
        "The assumption we are making is: **The meaning of documents are a function of the words they contain**  \n",
        "Let's build that!"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "3d7ee1ee-9f03-4ce7-89e3-675df596af8d",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Sample texts\n",
        "texts = df[\"Message\"].values\n",
        "\n",
        "# Create term-document matrix\n",
        "vectorizer = CountVectorizer()\n",
        "matrix = vectorizer.fit_transform(texts)\n",
        "\n",
        "# Convert to DataFrame for better visualization\n",
        "td_matrix = pd.DataFrame(matrix.toarray(), \n",
        "                 columns=vectorizer.get_feature_names_out(),\n",
        "                 index=[f'Doc{i+1}' for i in range(len(texts))])\n",
        "\n",
        "print(\"Term-document matrix:\")\n",
        "td_matrix"
      ],
      "metadata": {}
    },
    {
      "id": "19ebfc00-ba5b-40c6-a29d-ab1d7d3fd403",
      "cell_type": "markdown",
      "source": [
        "Very simple. You see the rows are documents and the columns are 'words'. We have word representations based on which documents they occur in (is this language modelling??) and we have document representations based on how many of each word they contain."
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "f0fdb7f7-cefb-46fc-8ac1-f89e3a1933e2",
      "cell_type": "markdown",
      "source": [
        "let's see the most frequent words"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "c3b59e2c-502f-4e3d-a865-6add0964c854",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "td_matrix.sum().sort_values(ascending=False).head(10)"
      ],
      "metadata": {}
    },
    {
      "id": "3768aac0-77a5-466d-b5ff-8b03eeede77a",
      "cell_type": "markdown",
      "source": [
        "We can infer our mostly co-occured words via vector similarity"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "0f849c36-efe2-471e-b1cf-dd7c25a1f08b",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def get_most_cooccurances(word, matrix_df, top_k=10):\n",
        "    if word not in matrix_df.columns:\n",
        "        raise Exception(f\"{word} does not exist in the vocabulary\")\n",
        "    vec = td_matrix[word].values\n",
        "    similarities = vec.dot(matrix.toarray())\n",
        "    top_k_indices = (-similarities).argsort()[:top_k]\n",
        "    return [matrix_df.iloc[:, i].name for i in top_k_indices]"
      ],
      "metadata": {}
    },
    {
      "id": "bcab1a50-257e-4ff5-9677-72160c29fce2",
      "cell_type": "markdown",
      "source": [
        "go ahead and discover what words co occur mostly, you can filter by spamness to infer how cooccurance differs between two classes"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "0c8cd4b7-88ce-4832-8ccd-d3ee252c37e7",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "get_most_cooccurances(\"cumalar\", td_matrix)"
      ],
      "metadata": {}
    },
    {
      "id": "4a6d0f06-3314-4338-b8c7-4003aa8f6d59",
      "cell_type": "markdown",
      "source": [
        "It sort of makes sense, but why is it so ugly?  \n",
        "The words are extracted naively. There are different vectors for \"düşünmek\", \"düşünüyorum\", \"düşündüler\" etc.\n",
        "Our assumption was that document meaning is a function of its words. We can also assume these words would contribute to similar meanings in a document, so treating them as seperate creates noise.  \n",
        "Also, words like \"ve\", \"veya\", \"şöyle\", \"böyle\" should contribute very little to the meaning. Getting rid of those should also remove some of the noise in the matrix"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "2a93605a-a7e5-4a2e-8a32-373f42996e07",
      "cell_type": "markdown",
      "source": [
        "### Exercise 2 \n",
        "go ahead and write preprocessing step to mitigate the problems stated above, you might remember terms like stop words, stemming and so on. Then, use your new and beautiful term occurances as features for the classifiers above and see how well it performs compared to your initial feature engineering."
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "1ab34f2e-7583-4d7a-8100-67ffedb68c0a",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        ""
      ],
      "metadata": {}
    },
    {
      "id": "ff45bca1-bb92-4821-a1d6-1b856c7a73e1",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        ""
      ],
      "metadata": {}
    },
    {
      "id": "4808fef8-3d1f-4fdd-b941-fb6315b5ffcf",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        ""
      ],
      "metadata": {}
    },
    {
      "id": "219e0423-6470-414b-add2-93cdc62676f3",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        ""
      ],
      "metadata": {}
    },
    {
      "id": "c4a3a7c6-5880-47ca-a6a9-68bb4fc9519d",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        ""
      ],
      "metadata": {}
    },
    {
      "id": "11ef7dd7-d3c3-4909-b76d-7d15199aefc9",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        ""
      ],
      "metadata": {}
    },
    {
      "id": "5e56b391-cc76-4851-9da6-28e334388372",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        ""
      ],
      "metadata": {}
    },
    {
      "id": "4b732bb0-92cf-496d-b847-678881b94697",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        ""
      ],
      "metadata": {}
    },
    {
      "id": "f474b5a3-3249-446a-b443-e230cb9811b7",
      "cell_type": "markdown",
      "source": [
        "# NLP Tasks"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "dda9b40b-0e98-4c82-a308-bfa4e1edd871",
      "cell_type": "markdown",
      "source": [
        "## Token Classification"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "dfa73f36-5256-4b65-a30a-1aca79d88bd1",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ],
      "metadata": {}
    },
    {
      "id": "488392df-9d17-4534-87a4-1236dbf2f91d",
      "cell_type": "markdown",
      "source": [
        "a tokenizer will be useful"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "a420a991-2adf-48d8-a6d7-f51d63073346",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "model_name = \"dbmdz/distilbert-base-turkish-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {}
    },
    {
      "id": "a96a870e-ed5d-4764-a89e-2ac032009f12",
      "cell_type": "markdown",
      "source": [
        "### NER"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "b7d9fe2b-79ec-4399-8a69-ea8bbcda39de",
      "cell_type": "markdown",
      "source": [
        "Token classification is about classifying the parts (words, subwords...) of a text.\n",
        "\n",
        "Most known application is Named Entity Recognition:\n",
        "\n",
        "- [ \"My\", \"name\", \"is\", \"Ahmet\", \".\" ]\n",
        "- [ \"O\", \"O\", \"O\", \"PERSON\", \"O\" ]  \n",
        "\n",
        "Named entity recognition finds the special entities in a text, such as \"person\", \"location\", \"date\".\n",
        "\n",
        "It is a type of token classification, classes being, for example, \"O\", \"PERSON\", \"LOC\", \"DATE\"."
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "5032b0f8-e34c-43b5-a154-dcb7265eff4c",
      "cell_type": "markdown",
      "source": [
        "#### How does the ner data look like?"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "68794c5b-4786-4793-a94f-2eb18a29f561",
      "cell_type": "markdown",
      "source": [
        "[turkish-nlp-suite/turkish-wikiNER](https://huggingface.co/datasets/turkish-nlp-suite/turkish-wikiNER)  \n",
        "[aynısının github linki](https://github.com/turkish-nlp-suite/Turkish-Wiki-NER-Dataset/)\n"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "05caf30c-bbae-4ef2-8fe7-4434bf46c8ff",
      "cell_type": "markdown",
      "source": [
        "I am reading the same data as pandas dataframe and huggingface Datasets to understand what Datasets has to offer and how do they differ"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "63cd07f7-cb50-45a8-a511-74e3b8a4a69c",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Loading dataset via pandas\n",
        "import pandas as pd\n",
        "\n",
        "splits = {'train': 'dataset/train.json', 'validation': 'dataset/valid.json', 'test': 'dataset/test.json'}\n",
        "df = pd.read_json(\"hf://datasets/turkish-nlp-suite/turkish-wikiNER/\" + splits[\"train\"], lines=True)"
      ],
      "metadata": {}
    },
    {
      "id": "14b5b673-e6c5-4f64-b58c-a1016bc8d36d",
      "cell_type": "markdown",
      "source": [
        "These are the classes represented in the dataset"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "fb51defb-3907-451a-9cdd-3e53f64c6471",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "label_list = ['O',\n",
        "'B-CARDINAL',\n",
        "'I-CARDINAL',\n",
        "'B-DATE',\n",
        "'I-DATE',\n",
        "'B-EVENT',\n",
        "'I-EVENT',\n",
        "'B-FAC',\n",
        "'I-FAC',\n",
        "'B-GPE',\n",
        "'I-GPE',\n",
        "'B-LANGUAGE',\n",
        "'I-LANGUAGE',\n",
        "'B-LAW',\n",
        "'I-LAW',\n",
        "'B-LOC',\n",
        "'I-LOC',\n",
        "'B-MONEY',\n",
        "'I-MONEY',\n",
        "'B-NORP',\n",
        "'I-NORP',\n",
        "'B-ORDINAL',\n",
        "'I-ORDINAL',\n",
        "'B-ORG',\n",
        "'I-ORG',\n",
        "'B-PERCENT',\n",
        "'I-PERCENT',\n",
        "'B-PERSON',\n",
        "'I-PERSON',\n",
        "'B-PRODUCT',\n",
        "'I-PRODUCT',\n",
        "'B-QUANTITY',\n",
        "'I-QUANTITY',\n",
        "'B-TIME',\n",
        "'I-TIME',\n",
        "'B-TITLE',\n",
        "'I-TITLE',\n",
        "'B-WORK_OF_ART',\n",
        "'I-WORK_OF_ART']"
      ],
      "metadata": {}
    },
    {
      "id": "0b6af039-63ff-455f-8c08-f26d1bbe676c",
      "cell_type": "markdown",
      "source": [
        "Let's take a look at what we are dealing with"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "e05f9f38-9510-408f-8c09-590599c23a01",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "df"
      ],
      "metadata": {}
    },
    {
      "id": "6b714249-f943-4ad6-a1a4-b73b9b4b305f",
      "cell_type": "markdown",
      "source": [
        "Here we see the labels are given for each word. But most modern approaches don't use word tokenization. We also will be using a model with subword tokenization. Subword tokenization is very beneficial with morphologically rich languages like Turkish."
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "b4cb95e9-7797-4de4-846e-8e6af643168a",
      "cell_type": "markdown",
      "source": [
        "In the function below we are aligning the labels with the actual tokens that our model will use.  \n",
        "Feel free to disect it"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "22743b54-0294-4b90-b944-d074c8324e46",
      "cell_type": "markdown",
      "source": [
        "Here we set the labels of all special tokens to -100 (the index that is ignored by PyTorch) and the labels of all other tokens to the label of the word they come from. Another strategy is to set the label only on the first token obtained from a given word, and give a label of -100 to the other subtokens from the same word. For more info check the [original notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/token_classification.ipynb#scrollTo=DIba90p4rvU_)"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "7b160f67-d2fe-474d-944d-3e9b000fbe90",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# How would the code change if we just assume we only want to label all tokens?\n",
        "\n",
        "label_all_tokens=True\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(examples[\"tokens\"],\n",
        "                                 truncation=True,\n",
        "                                 is_split_into_words=True)\n",
        "\n",
        "    word_ids = tokenized_inputs.word_ids()\n",
        "    previous_word_idx = None\n",
        "    label_ids = []\n",
        "    for word_idx in word_ids:\n",
        "         # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
        "        # ignored in the loss function.\n",
        "        if word_idx is None:\n",
        "            label_ids.append(-100)\n",
        "        # We set the label for the first token of each word.\n",
        "        elif word_idx != previous_word_idx:\n",
        "            label_ids.append(label_list.index(examples[\"tags\"][word_idx]))\n",
        "        # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
        "        # the label_all_tokens flag.\n",
        "        else:\n",
        "            label_ids.append(label_list.index(examples[\"tags\"][word_idx]) if label_all_tokens else -100)\n",
        "        previous_word_idx = word_idx\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = label_ids\n",
        "    #import pdb; pdb.set_trace()\n",
        "    return tokenized_inputs"
      ],
      "metadata": {}
    },
    {
      "id": "07dd10d8-b134-4608-8ec6-0cb8a0640c4f",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "tmp_df = df.progress_apply(tokenize_and_align_labels, axis=1)"
      ],
      "metadata": {}
    },
    {
      "id": "54c1d1f4-2ee4-4855-9511-9ae25a70e524",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "tokenized_df = pd.DataFrame(tmp_df.tolist()) # burayı başka bi şekilde yap"
      ],
      "metadata": {}
    },
    {
      "id": "febbba24-9fc7-48ef-a1e3-3bfac16b25a3",
      "cell_type": "markdown",
      "source": [
        "This is how the tokenized labels look like"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "4bc54849-f955-4ee2-839d-b422623ec12e",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# we can also add the decoded input_ids to peep into the tokenization of the actual text\n",
        "tokenized_df"
      ],
      "metadata": {}
    },
    {
      "id": "151b2ae5-9bb4-466d-bea5-9bfb4c953fc9",
      "cell_type": "markdown",
      "source": [
        "#### Finetuning NER"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "ca4a2216-385f-40f7-a85c-a90557962a7e",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer"
      ],
      "metadata": {}
    },
    {
      "id": "23c965f6-0e98-45ee-9748-c91624dd3acc",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(label_list))"
      ],
      "metadata": {
        "scrolled": true
      }
    },
    {
      "id": "ac679f65-824c-4406-90b7-212cb97c6c50",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "# Data collator that will dynamically pad the inputs received, as well as the labels.\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)"
      ],
      "metadata": {}
    },
    {
      "id": "08fc3604-002a-4df4-838b-bea1ca794579",
      "cell_type": "markdown",
      "source": [
        "It is a very convenient abstraction to use datasets library with transformers feel free to check how it differs from pandas df"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "5c9238d6-c31c-469b-a327-b6a7563d7edc",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import datasets\n",
        "split = round(len(tokenized_df)*0.3)\n",
        "print(split)\n",
        "\n",
        "dataset = datasets.DatasetDict(\n",
        "    {\n",
        "        \"train\": datasets.Dataset.from_pandas(tokenized_df[split:]),\n",
        "        \"test\": datasets.Dataset.from_pandas(tokenized_df[:split]),\n",
        "    }\n",
        ")"
      ],
      "metadata": {}
    },
    {
      "id": "9749dbf0-467f-44c1-b9ab-d8386deeb6af",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "args = TrainingArguments(\n",
        "    \"test-ner\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")"
      ],
      "metadata": {}
    },
    {
      "id": "7fab82ac-b4ba-4ee6-87b9-da29d9e81da4",
      "cell_type": "markdown",
      "source": [
        "The last thing to define for our Trainer is how to compute the metrics from the predictions. Here we will load the seqeval metric (which is commonly used to evaluate results on the CONLL dataset) via the Datasets library."
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "fad08322-c37a-48b3-b909-a2ea9c7e6bf2",
      "cell_type": "markdown",
      "source": [
        "So we will need to do a bit of post-processing on our predictions:\n",
        "- select the predicted index (with the maximum logit) for each token\n",
        "- convert it to its string label\n",
        "- ignore everywhere we set a label of -100\n",
        "\n",
        "The following function does all this post-processing on the result of `Trainer.evaluate` (which is a namedtuple containing predictions and labels) before applying the metric:"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "228888d0-5fcf-4382-8499-6bed790e7d39",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from seqeval.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    return {\n",
        "        \"precision\": precision_score(y_true=true_labels, y_pred=true_predictions),\n",
        "        \"recall\": recall_score(y_true=true_labels, y_pred=true_predictions),\n",
        "        \"f1\": f1_score(y_true=true_labels, y_pred=true_predictions),\n",
        "        \"accuracy\": accuracy_score(y_true=true_labels, y_pred=true_predictions)\n",
        "    }"
      ],
      "metadata": {}
    },
    {
      "id": "d19f8a80-2390-45bf-8841-f7ee8f3b954a",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {}
    },
    {
      "id": "c8774a7c-5647-4532-b055-92ce3d3288ef",
      "cell_type": "markdown",
      "source": [
        "I hope the next cell does not start your pc fan immediately"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "d0633d4d-5bd9-4e35-a11b-63559f2ac957",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "trainer.train()"
      ],
      "metadata": {}
    },
    {
      "id": "4c8c85aa-f13d-4911-9a70-9a729e43446d",
      "cell_type": "markdown",
      "source": [
        "Let's see how we did on the test set"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "0162bae2-fc98-4cb6-a15f-874d327ba9c7",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {}
    },
    {
      "id": "f03ff172-a8a0-40d7-9dfb-33cf7129c07e",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def compute_test_results():\n",
        "    predictions, labels, _ = trainer.predict(dataset[\"test\"])\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    return true_predictions, true_labels\n"
      ],
      "metadata": {}
    },
    {
      "id": "834b36f7-e55f-4696-83b6-d46ba4bacf4c",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "pred, label = compute_test_results()"
      ],
      "metadata": {}
    },
    {
      "id": "5b343a5d-8997-49b2-b07b-c4bd6bb16b2a",
      "cell_type": "markdown",
      "source": [
        "We can see example-wise accuracy scores"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "05c31e52-557c-417b-b469-2c37801066e0",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "for p, l in zip(pred, label):\n",
        "    a = [pp==ll for pp,ll in zip(p,l)]\n",
        "    print(sum(a)/len(a))"
      ],
      "metadata": {}
    },
    {
      "id": "3ff3d049-6ff8-49c2-a527-f45d72132cad",
      "cell_type": "markdown",
      "source": [
        "#### NER Inference"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "e08f1f2f-5e2f-4dbb-82be-46066c2381f7",
      "cell_type": "markdown",
      "source": [
        "Feel free to play with your examples to see what the model is good and bad at"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "42e45767-7cc5-4bca-b549-9b7ce6376222",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "example_sentence = \"Inzva'nın Taksim binasını Yağız hiç görmemiş.\""
      ],
      "metadata": {}
    },
    {
      "id": "4b6a1b91-bdaf-414e-804e-ac4938b56683",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "inputs = tokenizer(example_sentence, return_tensors=\"pt\", add_special_tokens=True)\n",
        "inputs[\"input_ids\"] = inputs[\"input_ids\"].to(device=model.device)\n",
        "inputs[\"attention_mask\"] = inputs[\"attention_mask\"].to(device=model.device)\n"
      ],
      "metadata": {}
    },
    {
      "id": "712dd0ea-7952-44ab-a17e-dbccd9eb83c3",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "outputs = model(**inputs)"
      ],
      "metadata": {}
    },
    {
      "id": "853ece24-f61f-423d-b3fe-519fba3f7a64",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "predicted_classes = outputs['logits'].argmax(axis=2).cpu().numpy()[0]"
      ],
      "metadata": {}
    },
    {
      "id": "3c6a64eb-de43-4782-bd1e-dcbd7891e989",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(ids=inputs[\"input_ids\"].cpu().numpy()[0], skip_special_tokens=False)"
      ],
      "metadata": {}
    },
    {
      "id": "c98c7585-07b9-42ba-be28-e370ac18eea4",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "for i, p in enumerate(predicted_classes):\n",
        "    if tokens[i] in [tokenizer.sep_token, tokenizer.cls_token]:\n",
        "        continue\n",
        "    print(f\"{tokens[i]} ----> {label_list[p]}\")"
      ],
      "metadata": {}
    },
    {
      "id": "46711946-81ee-4cc1-b710-032d72db174b",
      "cell_type": "markdown",
      "source": [
        "### Extractive QA"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "6e30a54a-731e-4a0d-a772-7c55663ecd49",
      "cell_type": "markdown",
      "source": [
        "Extractive QA can also be formulated as a token classification problem. Here extractive means that the answers is a span inside the given context. So we can train a model to predict for each token to find which token is the start token and which token is the end token."
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "378fdb7d-d41d-46df-b6ea-47f1bf4f7267",
      "cell_type": "markdown",
      "source": [
        "This is what the SQuAD data format looks like which is quite a common standard dataset and format for QA literature (a bit outdated imo)"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "2849a6bc-a8b6-4c4b-878f-69db04c31cd5",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "example_qa = {\n",
        "                \"data\": [\n",
        "                    {\n",
        "                        \"title\": \"Example\",\n",
        "                        \"paragraphs\": [\n",
        "                            {\n",
        "                                \"context\": \"The quick brown fox jumps over the lazy dog.\",\n",
        "                                \"qas\": [\n",
        "                                    {\n",
        "                                        \"question\": \"What does the fox jump over?\",\n",
        "                                        \"id\": \"q1\",\n",
        "                                        \"answers\": [\n",
        "                                            {\n",
        "                                                \"text\": \"the lazy dog\",\n",
        "                                                \"answer_start\": 32\n",
        "                                            }\n",
        "                                        ]\n",
        "                                    }\n",
        "                                ]\n",
        "                            }\n",
        "                        ]\n",
        "                    }\n",
        "                ],\n",
        "                \"version\": \"2.0\"\n",
        "            }"
      ],
      "metadata": {}
    },
    {
      "id": "866ea63c-e07c-47a0-ae11-7a1a46b42e2f",
      "cell_type": "markdown",
      "source": [
        "We will be demonstrating the Extractive QA Task with a translated SQuAD dataset. From our friends at Boun-tabilab\n",
        "[boun-tabi/squad_tr](https://huggingface.co/datasets/boun-tabi/squad_tr)"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "9d3529dc-8a2b-4f1d-b725-f32a7979fbad",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import gzip\n",
        "import json\n",
        "\n",
        "with gzip.open(\"SQuAD-TR/data/squad-tr-train-v1.0.0.json.gz\", \"r\") as f:\n",
        "   qa_data = json.loads(f.read().decode('utf-8'))"
      ],
      "metadata": {}
    },
    {
      "id": "7e8e4dd6-4836-4f40-8c45-e2b11bdfa315",
      "cell_type": "markdown",
      "source": [
        "This time we are directly jumping into the HF datasets format"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "4ba2e120-2720-4ee4-b67f-eb31344359b2",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "def json_to_dataset(data):\n",
        "    datalist = []\n",
        "    for title in tqdm(data):\n",
        "        for paragraph in title[\"paragraphs\"]:\n",
        "            for qa in paragraph[\"qas\"]:\n",
        "                if len(qa[\"answers\"]) == 0: # bunları dahil edip de kurgulanabilir aslında\n",
        "                    continue\n",
        "                example = {'id': qa['id'], 'title': title[\"title\"], 'context': paragraph['context'], 'question': qa['question'], 'answers': qa['answers'][0]}\n",
        "                datalist.append(example)\n",
        "    \n",
        "    return Dataset.from_list(datalist)"
      ],
      "metadata": {}
    },
    {
      "id": "b57b7f3e-9e9d-4dcc-8a54-dee56eaed2d7",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r",
            "100%|██████████| 10/10 [00:00<00:00, 1167.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "squad_tr = json_to_dataset(qa_data[\"data\"][:1]) # I am limiting the number of titles to 10 for faster computations"
      ],
      "metadata": {}
    },
    {
      "id": "55164fa0-b093-479d-8a9d-e01c44f059bc",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "squad_tr"
      ],
      "metadata": {}
    },
    {
      "id": "91349db0-f059-433a-a798-338db79483b3",
      "cell_type": "markdown",
      "source": [
        "Split the dataset's `train` split into a train and test set with the [train_test_split](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.train_test_split) method:"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "32ca1b0e-5a95-4e45-9e3e-7bd9e67baa6e",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "squad_tr = squad_tr.train_test_split(test_size=0.2)"
      ],
      "metadata": {}
    },
    {
      "id": "ddda31b5-4c41-4083-ad63-432a61356a71",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "squad_tr"
      ],
      "metadata": {}
    },
    {
      "id": "b1f5b053-4887-407d-9f51-9f07729325a7",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "squad_tr[\"train\"][0]"
      ],
      "metadata": {}
    },
    {
      "id": "22ef8226-3bd9-4fc8-a76f-b2fae73fa1f6",
      "cell_type": "markdown",
      "source": [
        "There are several important fields here:\n",
        "\n",
        "- `answers`: the starting location of the answer token and the answer text.\n",
        "- `context`: background information from which the model needs to extract the answer.\n",
        "- `question`: the question a model should answer.\n"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "4f634532-2712-4964-9138-cba3f3130993",
      "cell_type": "markdown",
      "source": [
        "#### Preprocesing"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "16e0dc02-0933-4bef-8b0a-ffbdad93caf3",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/distilbert-base-turkish-cased\")"
      ],
      "metadata": {}
    },
    {
      "id": "4c21a252-b00f-41e9-8313-639cc6b8f70d",
      "cell_type": "markdown",
      "source": [
        "There are a few preprocessing steps particular to question answering tasks you should be aware of:\n",
        "\n",
        "1. Some examples in a dataset may have a very long `context` that exceeds the maximum input length of the model. To deal with longer sequences, truncate only the `context` by setting `truncation=\"only_second\"`.\n",
        "2. Next, map the start and end positions of the answer to the original `context` by setting\n",
        "   `return_offset_mapping=True`.\n",
        "3. With the mapping in hand, now you can find the start and end tokens of the answer. Use the [sequence_ids](https://huggingface.co/docs/tokenizers/main/en/api/encoding#tokenizers.Encoding.sequence_ids) method to\n",
        "   find which part of the offset corresponds to the `question` and which corresponds to the `context`.\n",
        "\n",
        "Here is how you can create a function to truncate and map the start and end tokens of the `answer` to the `context`:"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "39501ff9-4cd9-4ff5-a502-6dcc200f4952",
      "cell_type": "markdown",
      "source": [
        "I recommend checking the videos [here](https://huggingface.co/docs/transformers/tasks/question_answering) for grasping the data format for extractive QA, I based most of this section of notebook from that tutorial"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "f6b75db9-ba9f-4ea0-947c-e31f67e45568",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=384,\n",
        "        truncation=\"only_second\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    answers = examples[\"answers\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        answer = answers[i]\n",
        "        #start_char = answer[\"answer_start\"][0]\n",
        "        #end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
        "        start_char = answer[\"answer_start\"]\n",
        "        end_char = answer[\"answer_start\"] + len(answer[\"text\"])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        context_end = idx - 1\n",
        "\n",
        "        # If the answer is not fully inside the context, label it (0, 0)\n",
        "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs"
      ],
      "metadata": {}
    },
    {
      "id": "a0f9711e-7f2b-46e0-9042-d36ffa2220eb",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r",
            "Map:  37%|███▋      | 1000/2696 [00:00<00:00, 2669.54 examples/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r",
            "Map:  74%|███████▍  | 2000/2696 [00:00<00:00, 2700.55 examples/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r",
            "Map: 100%|██████████| 2696/2696 [00:00<00:00, 2711.28 examples/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r",
            "Map: 100%|██████████| 2696/2696 [00:01<00:00, 2675.30 examples/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r",
            "Map:   0%|          | 0/675 [00:00<?, ? examples/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r",
            "Map: 100%|██████████| 675/675 [00:00<00:00, 2493.08 examples/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r",
            "Map: 100%|██████████| 675/675 [00:00<00:00, 2415.62 examples/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#tokenized_squad = squad.map(preprocess_function, batched=True, remove_columns=squad[\"train\"].column_names)\n",
        "tokenized_squad_tr = squad_tr.map(preprocess_function, batched=True, remove_columns=squad_tr[\"train\"].column_names)"
      ],
      "metadata": {}
    },
    {
      "id": "8403c539-7c86-4c3f-b088-25e34e4ffde6",
      "cell_type": "markdown",
      "source": [
        "Now create a batch of examples using [DefaultDataCollator](https://huggingface.co/docs/transformers/main/en/main_classes/data_collator#transformers.DefaultDataCollator). Unlike other data collators in 🤗 Transformers, the [DefaultDataCollator](https://huggingface.co/docs/transformers/main/en/main_classes/data_collator#transformers.DefaultDataCollator) does not apply any additional preprocessing such as padding."
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "ed0bb891-5c7c-4774-a023-ed8ad10f3b26",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from transformers import DefaultDataCollator\n",
        "\n",
        "data_collator = DefaultDataCollator()"
      ],
      "metadata": {}
    },
    {
      "id": "7164eaf9-1cd3-410c-bbd7-a5fae7fea2fb",
      "cell_type": "markdown",
      "source": [
        "#### Training"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "4ea99af7-79e9-4cf7-b38a-840f043ce6e4",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"dbmdz/distilbert-base-turkish-cased\", device_map=\"cpu\")"
      ],
      "metadata": {}
    },
    {
      "id": "7fc7874a-351a-4c3a-9c1b-f85a9a48d174",
      "cell_type": "markdown",
      "source": [
        "As a side note, let's see what huggingface mean by \"model for question answering\" can you spot the difference between when we read the same model as a base model"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "ba7c2627-a6b9-48c5-bcda-83c343866948",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "model"
      ],
      "metadata": {}
    },
    {
      "id": "08b3ec4b-16de-4049-96d6-be7efc9aae40",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "base_model = AutoModel.from_pretrained(\"dbmdz/distilbert-base-turkish-cased\")"
      ],
      "metadata": {}
    },
    {
      "id": "623beea2-d0b8-4efb-aeb1-fcaaf90154da",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "base_model"
      ],
      "metadata": {}
    },
    {
      "id": "8150feca-bca7-4cb4-9248-2e81f93713ba",
      "cell_type": "markdown",
      "source": [
        "At this point, only three steps remain:\n",
        "\n",
        "1. Define your training hyperparameters in [TrainingArguments](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments). The only required parameter is `output_dir` which specifies where to save your model. You'll push this model to the Hub by setting `push_to_hub=True` (you need to be signed in to Hugging Face to upload your model).\n",
        "2. Pass the training arguments to [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) along with the model, dataset, tokenizer, and data collator.\n",
        "3. Call [train()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train) to finetune your model."
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "22baecd9-f1a4-4fe0-be3e-d5ec81f07e9d",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"test-squad-tr\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_squad_tr[\"train\"],\n",
        "    eval_dataset=tokenized_squad_tr[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n"
      ],
      "metadata": {}
    },
    {
      "id": "e18bb6bb-f11b-47eb-a6a5-3c3d16682e3d",
      "cell_type": "markdown",
      "source": [
        "Let's write a function to peep into what our data looks like at this stage"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "6fbe2199-1296-450f-bda2-518072501f6f",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def input_data_viewer(data):\n",
        "    tokens = data[\"input_ids\"]\n",
        "    padding_start = tokens.index(tokenizer.pad_token_id)\n",
        "    tokens = tokens[:padding_start]\n",
        "\n",
        "    #get the answer within\n",
        "    start = data[\"start_positions\"]\n",
        "    end = data[\"end_positions\"]\n",
        "\n",
        "    for idx, token in enumerate(tokens):\n",
        "        if idx == start:\n",
        "            print(\"<<<\", end=\" \")\n",
        "        print(tokenizer.decode(token), end=\" \")\n",
        "        if idx == end:\n",
        "            print(\">>>\", end=\" \")\n",
        "        "
      ],
      "metadata": {}
    },
    {
      "id": "74a103ba-12ae-4948-8db0-d5f0a029c013",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "input_data_viewer(tokenized_squad_tr[\"train\"][2])"
      ],
      "metadata": {}
    },
    {
      "id": "5f93134e-bf71-4bfb-b37b-2dccef5c13d9",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "tokenized_squad_tr"
      ],
      "metadata": {}
    },
    {
      "id": "5e2c1173-fa3e-4106-9081-b759fe0e40aa",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "trainer.train()"
      ],
      "metadata": {}
    },
    {
      "id": "bdeb8dda-7597-4fbb-b59d-4092d1cc2a97",
      "cell_type": "markdown",
      "source": [
        "#### Inference"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "1308dd8d-fb0d-462b-ae3e-30a2e24fff30",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "question = \"SQuAD veriseti ne zaman yayınlandı?\"\n",
        "context = \"The Stanford Question Answering Dataset yani SQuAD veriseti 2016 yılında akademik bir kıyaslama veriseti olarak yayınlandı ancak içerdiği basit örnekler eleştirilere sebep oldu\""
      ],
      "metadata": {}
    },
    {
      "id": "4b38f585-dd89-468f-a4c6-b76f2f34d11f",
      "cell_type": "markdown",
      "source": [
        "Tokenize the text and return PyTorch tensors:"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "c2843fef-9257-4cbd-b611-85892fbb924b",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "inputs = tokenizer(question, context, return_tensors=\"pt\")"
      ],
      "metadata": {
        "scrolled": true
      }
    },
    {
      "id": "d75e16f2-a358-4948-9064-fcbc8db1557c",
      "cell_type": "markdown",
      "source": [
        "Pass your inputs to the model and return the `logits`:"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "4118c481-bc10-4b1e-aa05-aa5f4ab8589a",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)"
      ],
      "metadata": {}
    },
    {
      "id": "4f14345f-563c-4ca7-ad0f-ce3d9c339fc5",
      "cell_type": "markdown",
      "source": [
        "Get the highest probability from the model output for the start and end positions:"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "43869e88-ebfb-4e3b-bf71-18459ca72c9b",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "answer_start_index = outputs.start_logits.argmax()\n",
        "answer_end_index = outputs.end_logits.argmax()"
      ],
      "metadata": {}
    },
    {
      "id": "44943378-bffa-4c40-ac15-7b833c1b8e36",
      "cell_type": "markdown",
      "source": [
        "Decode the predicted tokens to get the answer:"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "1e256334-860f-4801-b67e-8743939061f3",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
        "tokenizer.decode(predict_answer_tokens)"
      ],
      "metadata": {}
    },
    {
      "id": "0afd4414-d499-49ee-ba7e-bf01f68f451f",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        ""
      ],
      "metadata": {}
    },
    {
      "id": "8cbcdfda-7550-4b74-82ac-c5572ad7b875",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        ""
      ],
      "metadata": {}
    },
    {
      "id": "1ec56a29-7373-41cd-8725-a5fdabe23f18",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        ""
      ],
      "metadata": {}
    },
    {
      "id": "1050c0c6-6acc-4ca5-bf92-25e98c150305",
      "cell_type": "markdown",
      "source": [
        "## Sequence Classification"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "bb025310-7380-448e-9521-e9ca2dc4a9ff",
      "cell_type": "markdown",
      "source": [
        "The first example of this notebook was about classification. Sentiment Analysis is one of the most popular sequence classification tasks. Do you think we can formulate a question answering problem as a sequence classification task???"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "6809ec9f-0e5c-4ba9-a572-8546a49a69de",
      "cell_type": "markdown",
      "source": [
        "### Sentiment analysis"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "a35151a1-62a1-4e0a-abf5-67c49a5a8f1a",
      "cell_type": "markdown",
      "source": [
        "[winvoker/turkish-sentiment-analysis-dataset](https://huggingface.co/datasets/winvoker/turkish-sentiment-analysis-dataset)"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "3401cfe2-5807-4508-a503-d654c4c75c8b",
      "cell_type": "markdown",
      "source": [
        "Checking the sequence classification class of bert models will give us an idea about how this problem that we tried to solve with ancient methods, can be solved with language models"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "d6af410a-73be-414d-a714-25a16ba6750b",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification"
      ],
      "metadata": {}
    },
    {
      "id": "0bbc4cf5-3af4-47eb-a0dc-2099df76569c",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "sc_model = BertForSequenceClassification.from_pretrained(\"dbmdz/bert-base-turkish-cased\")"
      ],
      "metadata": {}
    },
    {
      "id": "40c93e8a-8e47-4403-8e88-de5a80e9727c",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "sc_model"
      ],
      "metadata": {}
    },
    {
      "id": "8b5e3a8d-a65d-49cd-b5b3-d677a5cfb24f",
      "cell_type": "markdown",
      "source": [
        "## Language Modeling"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "8723b9c0-6391-4547-94e3-e560e2213447",
      "cell_type": "markdown",
      "source": [
        "### Encoder Models"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "14876fd0-1308-4384-b7d7-d0faf635bd96",
      "cell_type": "markdown",
      "source": [
        "Modern encoder models take a natural language input and return a contextualised representation of the input.\n",
        "(still) The most popular and influencial encoder model is BERT."
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "b709b5b4-7245-408c-b566-25342abd849d",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")\n",
        "model = AutoModel.from_pretrained(\"dbmdz/bert-base-turkish-cased\")"
      ],
      "metadata": {}
    },
    {
      "id": "eb8e2e31-097e-4a61-9993-1218c3ada1c8",
      "cell_type": "markdown",
      "source": [
        "Let's see what happens to our text input when passed through an encoder model"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "889ee66e-ea1f-4d89-abec-708f87dc24f4",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "%%time\n",
        "s = \"Bir zamanlar BERTten büyük dil model diye bahsedilirdi...\"\n",
        "inputs = tokenizer(s, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)"
      ],
      "metadata": {}
    },
    {
      "id": "d5c8ad39-624a-4418-8dca-ba0995cd80df",
      "cell_type": "markdown",
      "source": [
        "inputs are familiar at this point"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "95aca1e6-029b-4664-a665-62b221d329e6",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "inputs"
      ],
      "metadata": {}
    },
    {
      "id": "64198ab8-8f6d-4dc8-a0bb-c06fefad3e2d",
      "cell_type": "markdown",
      "source": [
        "Let's see what the outputs have to offer"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "11b1e0a6-44f3-4039-a13e-c499b7740bef",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "outputs.__dict__.keys()"
      ],
      "metadata": {}
    },
    {
      "id": "69f758f5-ff9d-4a42-ad5c-e26ecdb17d7c",
      "cell_type": "markdown",
      "source": [
        "Let's dive into what are those and what use they have"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "8873d519-6b22-4981-ba05-20b215b58b97",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "outputs.last_hidden_state.shape"
      ],
      "metadata": {}
    },
    {
      "id": "a179c4ae-a97e-42f9-bb03-1eb2df307155",
      "cell_type": "markdown",
      "source": [
        "Last hidden state of BERT is shaped like [batch_size, input_token_size, embedding_size] so it generates an embedding vector for each token, which we have utilized for token classification tasks before"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "0d206f31-f67c-48f4-99e2-543619c82b62",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "outputs.pooler_output.shape"
      ],
      "metadata": {}
    },
    {
      "id": "730239cd-8e89-4713-9c3d-5d315aa7fcf2",
      "cell_type": "markdown",
      "source": [
        "Pooler output is (although implementations may differ between bert variants) the CLS token embedding went through a linear layer and tanh activation. This is mostly used for sentence embeddings."
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "75c791a3-8a7d-4dc5-896b-b6182b27f8c0",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "outputs.pooler_output"
      ],
      "metadata": {
        "scrolled": true
      }
    },
    {
      "id": "4e60ec9d-79a6-43f0-8062-fa56ba9e981a",
      "cell_type": "markdown",
      "source": [
        "### Exercise?? if you want so"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "8df8b0f7-b562-4787-80ba-81a97a7b2aa6",
      "cell_type": "markdown",
      "source": [
        "**This is basically a 768 dimentional feature vector. You can use this for the very first problem in this notebook and see how it compares!**"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "95331079-5350-4990-a045-c98788d0c060",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        ""
      ],
      "metadata": {}
    },
    {
      "id": "9d330850-6363-4045-a4ab-5f668da1c875",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        ""
      ],
      "metadata": {}
    },
    {
      "id": "c45d10a7-6b77-4151-b6ad-72b15ba01414",
      "cell_type": "markdown",
      "source": [
        "### Encoder - Decoder Models"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "b38fb4cf-4346-4481-b87d-49c4a5a3fb38",
      "cell_type": "markdown",
      "source": [
        "Encoder - Decoder Models are mostly used for sequence-to-sequence NLP problems. Such as translation, summarization, generative question answering and so on."
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "1a288118-aa22-4714-be2f-eb39d04e8488",
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/Users/ygzipekci/Library/Application Support/Satyrn/venvs/test_098f6bcd/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Config of the encoder: <class 'transformers.models.bert.modeling_bert.BertModel'> is overwritten by shared encoder config: BertConfig {\n",
            "  \"_name_or_path\": \"dbmdz/bert-base-turkish-cased\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.49.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "Config of the decoder: <class 'transformers.models.bert.modeling_bert.BertLMHeadModel'> is overwritten by shared decoder config: BertConfig {\n",
            "  \"_name_or_path\": \"dbmdz/bert-base-turkish-cased\",\n",
            "  \"add_cross_attention\": true,\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": true,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.49.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "/Users/ygzipekci/Library/Application Support/Satyrn/venvs/test_098f6bcd/.venv/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"ahmetbagci/bert2bert-turkish-paraphrase-generation\")\n",
        "\n",
        "t5tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")\n",
        "t5model = AutoModelForSeq2SeqLM.from_pretrained(\"google/mt5-small\")\n"
      ],
      "metadata": {}
    },
    {
      "id": "0a05d51c-7c3d-41ef-8aac-6493b72dd1cb",
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": null,
          "data": {
            "text/plain": [
              "MT5ForConditionalGeneration(\n",
              "  (shared): Embedding(250112, 512)\n",
              "  (encoder): MT5Stack(\n",
              "    (embed_tokens): Embedding(250112, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): MT5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): MT5LayerSelfAttention(\n",
              "            (SelfAttention): MT5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 6)\n",
              "            )\n",
              "            (layer_norm): MT5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): MT5LayerFF(\n",
              "            (DenseReluDense): MT5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): MT5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-7): 7 x MT5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): MT5LayerSelfAttention(\n",
              "            (SelfAttention): MT5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): MT5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): MT5LayerFF(\n",
              "            (DenseReluDense): MT5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): MT5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): MT5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): MT5Stack(\n",
              "    (embed_tokens): Embedding(250112, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): MT5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): MT5LayerSelfAttention(\n",
              "            (SelfAttention): MT5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 6)\n",
              "            )\n",
              "            (layer_norm): MT5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): MT5LayerCrossAttention(\n",
              "            (EncDecAttention): MT5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): MT5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): MT5LayerFF(\n",
              "            (DenseReluDense): MT5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): MT5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-7): 7 x MT5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): MT5LayerSelfAttention(\n",
              "            (SelfAttention): MT5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): MT5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): MT5LayerCrossAttention(\n",
              "            (EncDecAttention): MT5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): MT5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): MT5LayerFF(\n",
              "            (DenseReluDense): MT5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): MT5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): MT5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=250112, bias=False)\n",
              ")"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "t5model"
      ],
      "metadata": {}
    },
    {
      "id": "38b72466-f822-4462-931c-101db95523b9",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "text = \"beni benden alırsan seni sana bırakmam\"\n",
        "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
        "output_ids = model.generate(input_ids)\n",
        "print(tokenizer.decode(output_ids[0], skip_special_tokens=True))"
      ],
      "metadata": {}
    },
    {
      "id": "e3be3904-1860-4f51-9b4f-5d6be84556d6",
      "cell_type": "markdown",
      "source": [
        "### Decoder Models"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "d3ca4219-39a8-4599-b04f-51b78d0ff947",
      "cell_type": "markdown",
      "source": [
        "Decoder Models are all the fuzz since chatgpt. Let's look into their workings"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "49674eac-cfa5-45b1-8ef8-a26c305d25ba",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ],
      "metadata": {}
    },
    {
      "id": "ee577bc5-5480-4913-8c67-89b0aa27d3c3",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilgpt2\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"distilbert/distilgpt2\")"
      ],
      "metadata": {}
    },
    {
      "id": "3aae5557-7939-4ba4-a35b-f4435231aaec",
      "cell_type": "markdown",
      "source": [
        "We are going to look into instruction tuning."
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "f69d0b7e-5b52-42f7-8e9a-3fcbe1ef8d30",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"BrewInteractive/alpaca-tr\")"
      ],
      "metadata": {}
    },
    {
      "id": "3934146a-f05e-461a-b9e7-1798aebe2b59",
      "cell_type": "markdown",
      "source": [
        "We know that decoder only models are autoregressive next-token predictors. Their task is also called \"document completion\" because the continue writing whatever the input document was.  \n",
        "But how come models that just make more of the input receive dialog capabilities?"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "e21e5e0e-9cd7-43a9-8074-53fe311eed60",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "tokenizer.chat_template = \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\"\n",
        "def form_prompts(examples):\n",
        "    prompts = {}\n",
        "    if examples[\"input\"]:\n",
        "        messages = [\n",
        "            {\"role\": \"user\", \"content\": examples[\"instruction\"]},\n",
        "            {\"role\": \"context\", \"content\": examples[\"input\"]},\n",
        "            {\"role\": \"assistant\", \"content\": examples[\"output\"]}\n",
        "        ]\n",
        "    else:\n",
        "        messages = [\n",
        "            {\"role\": \"user\", \"content\": examples[\"instruction\"]},\n",
        "            {\"role\": \"assistant\", \"content\": examples[\"output\"]}\n",
        "        ]\n",
        "    prompts[\"prompt\"] = tokenizer.apply_chat_template(messages, tokenize=False)\n",
        "    prompts[\"input_ids\"] = tokenizer.apply_chat_template(messages, tokenize=True, truncation=True)\n",
        "    return {\"input_ids\": prompts[\"input_ids\"]}"
      ],
      "metadata": {}
    },
    {
      "id": "f7b921f2-72fb-40f5-98ec-4569d553d4f1",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "ds = ds.map(batched_form_prompts, remove_columns=ds[\"train\"].column_names, batched=True)"
      ],
      "metadata": {}
    },
    {
      "id": "a3b5ee12-2504-4c86-8d39-8d5a51ff9e99",
      "cell_type": "markdown",
      "source": [
        "So yes it is still document completion but the document looks in a very specific format"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "7d93b4e4-7f3e-4497-bbe3-dc8248e2e5bf",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "ds = ds[\"train\"].train_test_split(test_size=0.2)"
      ],
      "metadata": {}
    },
    {
      "id": "1368ff21-8a16-40ea-9eb8-140a81e73956",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "ds"
      ],
      "metadata": {}
    },
    {
      "id": "1d7168f3-4453-445b-8433-198b64b27dd7",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "chat = [\n",
        "  {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
        "  {\"role\": \"assistant\", \"content\": \"I'm doing great. How can I help you today?\"},\n",
        "  {\"role\": \"user\", \"content\": \"I'd like to show off how chat templating works!\"},\n",
        "]\n",
        "\n",
        "print(tokenizer.apply_chat_template(chat, tokenize=False))\n"
      ],
      "metadata": {}
    },
    {
      "id": "53134a0d-3418-4001-be8c-9f0cbc52ee8a",
      "cell_type": "markdown",
      "source": [
        "Every dialog with any instruction model is parsed into a single string at the background"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "ad11dbfe-e3fb-438d-96c3-2525fed29050",
      "cell_type": "markdown",
      "source": [
        "**Extras** What is lora how does it work why does it work?"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "e1faade8-99b4-408a-83d3-514b09ef8079",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "model"
      ],
      "metadata": {}
    },
    {
      "id": "efbfd58d-4702-4d37-a848-b02d5e40ce63",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from transformers import BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "\n",
        "target_modules = [\"c_attn\"]\n",
        "config = LoraConfig(\n",
        "    r=1,\n",
        "    lora_alpha=16, \n",
        "    target_modules=target_modules, \n",
        "    lora_dropout=0.1, \n",
        "    bias=\"none\", \n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "lora_model = get_peft_model(model, config)"
      ],
      "metadata": {}
    },
    {
      "id": "521201c8-7651-48ad-aa8e-6963a0a7fb34",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "lora_model.print_trainable_parameters()"
      ],
      "metadata": {}
    },
    {
      "id": "eb2a2c07-ec7b-42ba-aded-1d9e83fdcaba",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling, TrainingArguments, Trainer\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"gpt2_alpaca_tr\",\n",
        "    eval_strategy=\"no\",\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    use_cpu=True\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=lora_model,\n",
        "    args=training_args,\n",
        "    train_dataset=ds[\"train\"], # datanın neye benzemesi gerekiyo bi bak\n",
        "    eval_dataset=ds[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")\n"
      ],
      "metadata": {}
    },
    {
      "id": "0e26158d-7e99-4fe7-8c88-e09ad95f66b6",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "ds[\"train\"][0]"
      ],
      "metadata": {}
    },
    {
      "id": "110d8214-dde2-41a6-ac2b-b3f37a013143",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "lora_model.device"
      ],
      "metadata": {}
    },
    {
      "id": "db5d9f6b-5729-4af6-9604-1ceffd2eb088",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "trainer.train()"
      ],
      "metadata": {}
    },
    {
      "id": "da9a8d6f-17cc-4e4e-863f-e3728081f155",
      "cell_type": "markdown",
      "source": [
        "### Inferance"
      ],
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "546e87d9-5ae4-4872-930c-40c5592c3853",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "prompt = \"Somatic hypermutation allows the immune system to\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "outputs = model.generate(inputs, max_new_tokens=100, do_sample=True, top_k=50, top_p=0.95)"
      ],
      "metadata": {}
    },
    {
      "id": "240f4ef7-4566-4094-a542-340b61678883",
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "test",
      "display_name": "inzva_w1",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}